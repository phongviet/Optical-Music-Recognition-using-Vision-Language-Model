<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/PREPROCESSING_USAGE.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/PREPROCESSING_USAGE.md" />
              <option name="updatedContent" value="# Preprocessing Script - Updated Usage Guide&#10;&#10;## ✅ Integration Complete&#10;&#10;The command-line interface has been **integrated directly into `preprocess.py`**. You no longer need a separate `run_preprocessing.py` script!&#10;&#10;##  Usage&#10;&#10;### Option 1: Run with Default Settings (Simplest)&#10;```bash&#10;python src\dataset\preprocess.py&#10;```&#10;&#10;### Option 2: Run with Custom Workers&#10;```bash&#10;python src\dataset\preprocess.py --workers 8&#10;```&#10;&#10;### Option 3: Run with All Custom Parameters&#10;```bash&#10;python src\dataset\preprocess.py \&#10;    --png-root data/png \&#10;    --abc-root data/abc \&#10;    --output-png data/processed/png \&#10;    --output-abc data/processed/abc \&#10;    --metadata data/metadata.csv \&#10;    --workers 16&#10;```&#10;&#10;### Option 4: Get Help&#10;```bash&#10;python src\dataset\preprocess.py --help&#10;```&#10;&#10;##  Available Arguments&#10;&#10;| Argument | Type | Default | Description |&#10;|----------|------|---------|-------------|&#10;| `--workers` | int | auto | Number of worker threads |&#10;| `--png-root` | str | `data/png` | Source PNG directory |&#10;| `--abc-root` | str | `data/abc` | Source ABC directory |&#10;| `--output-png` | str | `data/processed/png` | Output PNG directory |&#10;| `--output-abc` | str | `data/processed/abc` | Output ABC directory |&#10;| `--metadata` | str | `data/metadata.csv` | Output metadata CSV file |&#10;&#10;##  Examples&#10;&#10;### Process with auto-detected workers (recommended)&#10;```bash&#10;python src\dataset\preprocess.py&#10;```&#10;&#10;### Process with 4 workers (for systems with limited RAM)&#10;```bash&#10;python src\dataset\preprocess.py --workers 4&#10;```&#10;&#10;### Process with 16 workers (for high-end systems)&#10;```bash&#10;python src\dataset\preprocess.py --workers 16&#10;```&#10;&#10;### Process with custom paths&#10;```bash&#10;python src\dataset\preprocess.py \&#10;    --png-root my_custom_png_folder \&#10;    --abc-root my_custom_abc_folder \&#10;    --output-png output/png \&#10;    --output-abc output/abc \&#10;    --metadata output/metadata.csv&#10;```&#10;&#10;### Single-threaded for debugging&#10;```bash&#10;python src\dataset\preprocess.py --workers 1&#10;```&#10;&#10;##  Programmatic Usage&#10;&#10;You can still use it programmatically in your Python scripts:&#10;&#10;```python&#10;from src.dataset.preprocess import preprocess_dataset&#10;&#10;# Default settings&#10;preprocess_dataset()&#10;&#10;# Custom settings&#10;preprocess_dataset(&#10;    png_root=&quot;data/png&quot;,&#10;    abc_root=&quot;data/abc&quot;,&#10;    output_png_dir=&quot;data/processed/png&quot;,&#10;    output_abc_dir=&quot;data/processed/abc&quot;,&#10;    metadata_csv=&quot;data/metadata.csv&quot;,&#10;    num_workers=8&#10;)&#10;```&#10;&#10;##  Expected Output&#10;&#10;```&#10;============================================================&#10;Sheet Music Preprocessing Pipeline&#10;============================================================&#10;PNG source: data/png&#10;ABC source: data/abc&#10;PNG output: data/processed/png&#10;ABC output: data/processed/abc&#10;Metadata CSV: data/metadata.csv&#10;Workers: auto&#10;============================================================&#10;&#10;Finding all PNG files...&#10;Found 5000 unique sheet music pieces&#10;&#10;Processing sheet music files with auto workers...&#10;Processing: 100%|████████████████| 5000/5000 [02:15&lt;00:00, 36.89it/s]&#10;&#10;Writing metadata to data/metadata.csv...&#10;&#10;============================================================&#10;Preprocessing complete!&#10;============================================================&#10;Processed: 4850 sheet music pieces&#10;Skipped: 150 pieces (no matching ABC file)&#10;Output PNG directory: data/processed/png&#10;Output ABC directory: data/processed/abc&#10;Metadata CSV: data/metadata.csv&#10;============================================================&#10;```&#10;&#10;##  What Changed?&#10;&#10;### Before:&#10;- Needed to run: `python scripts/run_preprocessing.py --workers 8`&#10;- Two files: `preprocess.py` + `run_preprocessing.py`&#10;&#10;### After:&#10;- Run directly: `python src/dataset/preprocess.py --workers 8`&#10;- One file: `preprocess.py` (with integrated CLI)&#10;&#10;## ✨ Benefits&#10;&#10;- ✅ **Simpler**: Only one file to maintain&#10;- ✅ **Cleaner**: No separate wrapper script needed&#10;- ✅ **More intuitive**: CLI is part of the main script&#10;- ✅ **Still flexible**: Same command-line options available&#10;- ✅ **Backwards compatible**: Programmatic usage unchanged&#10;&#10;##  Testing&#10;&#10;Run the test script to verify everything works:&#10;&#10;```bash&#10;python scripts\test_preprocessing.py&#10;```&#10;&#10;This will create sample data and verify the preprocessing works correctly.&#10;&#10;---&#10;&#10;**Note**: The old `scripts/run_preprocessing.py` is now deprecated and can be deleted. All functionality is integrated into `src/dataset/preprocess.py`.&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>